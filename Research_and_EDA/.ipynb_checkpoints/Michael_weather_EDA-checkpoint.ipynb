{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data, view dtypes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create path for train.csv and weather.csv\n",
    "\n",
    "path_train = '/Users/michaelshea/desktop/class/WestNile/WestNilePrediction/Assets/train.csv'\n",
    "path_weather = '/Users/michaelshea/desktop/class/WestNile/WestNilePrediction/Assets/weather.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in dataframes\n",
    "\n",
    "train = pd.read_csv(path_train)\n",
    "weather = pd.read_csv(path_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                       object\n",
      "Address                    object\n",
      "Species                    object\n",
      "Block                       int64\n",
      "Street                     object\n",
      "Trap                       object\n",
      "AddressNumberAndStreet     object\n",
      "Latitude                  float64\n",
      "Longitude                 float64\n",
      "AddressAccuracy             int64\n",
      "NumMosquitos                int64\n",
      "WnvPresent                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Dtypes and columns of train_df \n",
    "\n",
    "print train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert train.Date to datetime\n",
    "\n",
    "train['Date'] = pd.to_datetime(train.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station          int64\n",
      "Date            object\n",
      "Tmax             int64\n",
      "Tmin             int64\n",
      "Tavg            object\n",
      "Depart          object\n",
      "DewPoint         int64\n",
      "WetBulb         object\n",
      "Heat            object\n",
      "Cool            object\n",
      "Sunrise         object\n",
      "Sunset          object\n",
      "CodeSum         object\n",
      "Depth           object\n",
      "Water1          object\n",
      "SnowFall        object\n",
      "PrecipTotal     object\n",
      "StnPressure     object\n",
      "SeaLevel        object\n",
      "ResultSpeed    float64\n",
      "ResultDir        int64\n",
      "AvgSpeed        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Dtypes and columns of weather_df\n",
    "\n",
    "print weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert weather Station to object\n",
    "\n",
    "weather['Station'] = weather.Station.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert weather Date column to datetime\n",
    "\n",
    "weather['Date'] = pd.to_datetime(weather.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set weather index to Date\n",
    "\n",
    "weather.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-05-01 00:00:00\n",
      "2014-10-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Find Date range of weather data\n",
    "\n",
    "print weather.index.min()\n",
    "print weather.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472\n"
     ]
    }
   ],
   "source": [
    "# Was weather measured every day? Every weekday?\n",
    "# According to internet, there were 2741 days between the dates above, 1886 excluding weekends and public holidays\n",
    "\n",
    "# This proves weather not measured everyday (just something to note going forward):\n",
    "print len(weather.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since test set includes 2008, 2010, 2012, and 2014, pull out these years from weather\n",
    "\n",
    "weather = weather[(weather.index.year == 2007) | (weather.index.year == 2009) | (weather.index.year == 2011) | (weather.index.year == 2013)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2007 2009 2011 2013]\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate above code worked:\n",
    "\n",
    "print np.unique(weather.index.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance between weather station and mosquito trap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are two weather stations, it might make sense to calculate the distance between each trap and the nearest weather station, and then use that station's weather data when we merge. The following link is what I found when I googled \"calculate distance between two points latitude longitude python\": http://www.johndcook.com/blog/python_longitude_latitude/\n",
    "\n",
    "It uses this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    " \n",
    "def distance_on_unit_sphere(lat1, long1, lat2, long2):\n",
    "\n",
    "    # Convert latitude and longitude to spherical coordinates in radians\n",
    "    degrees_to_radians = math.pi/180.0\n",
    " \n",
    "    # phi = 90 - latitude\n",
    "    phi1 = (90.0 - lat1)*degrees_to_radians\n",
    "    phi2 = (90.0 - lat2)*degrees_to_radians\n",
    " \n",
    "    # theta = longitude\n",
    "    theta1 = long1*degrees_to_radians\n",
    "    theta2 = long2*degrees_to_radians\n",
    " \n",
    "    # Compute spherical distance from spherical coordinates.\n",
    " \n",
    "    # For two locations in spherical coordinates\n",
    "    # (1, theta, phi) and (1, theta', phi')\n",
    "    # cosine( arc length ) =\n",
    "    # sin phi sin phi' cos(theta-theta') + cos phi cos phi'\n",
    "    # distance = rho * arc length\n",
    " \n",
    "    cos = (math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2) +\n",
    "    math.cos(phi1)*math.cos(phi2))\n",
    "    arc = math.acos( cos )\n",
    "\n",
    "    # Remember to multiply arc by the radius of the earth\n",
    "    # in your favorite set of units to get length.\n",
    "    return arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We could add a new column called closest_station to the train dataframe\n",
    "\n",
    "station_1_lat = 41.995\n",
    "station_1_lon = -87.933\n",
    "station_2_lat = 41.786\n",
    "station_2_lon = -87.752\n",
    "dist_to_station_1 = []\n",
    "dist_to_station_2 = []\n",
    "closest_station = []\n",
    "\n",
    "for i in range(len(train.index)):\n",
    "    one = distance_on_unit_sphere(train.ix[i, 'Latitude'], train.ix[i, 'Longitude'], station_1_lat, station_1_lon)\n",
    "    two = distance_on_unit_sphere(train.ix[i, 'Latitude'], train.ix[i, 'Longitude'], station_2_lat, station_2_lon)\n",
    "    if dist_to_station_1 > dist_to_station_2:\n",
    "        closest_station.append('1')\n",
    "    else:\n",
    "        closest_station.append('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now add closest_station column to weather stations to train dataframe\n",
    "\n",
    "train['closest_station'] = closest_station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unique identifier for table merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a unique identifier column to both train and weather dataframes by combining timestamp and weather station\n",
    "\n",
    "train['date_station_id'] = train[\"Date\"].map(str) + train[\"closest_station\"]\n",
    "\n",
    "weather['date_station_id'] = weather.index.map(str) + weather.Station.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-05-29 00:00:002\n",
      "2007-06-05 00:00:002\n",
      "2007-06-26 00:00:002\n",
      "2007-06-29 00:00:002\n",
      "2007-07-02 00:00:002\n",
      "2007-07-11 00:00:002\n",
      "2007-07-18 00:00:002\n",
      "2007-07-19 00:00:002\n",
      "2007-07-25 00:00:002\n",
      "2007-07-27 00:00:002\n",
      "2007-08-01 00:00:002\n",
      "2007-08-02 00:00:002\n",
      "2007-08-03 00:00:002\n",
      "2007-08-07 00:00:002\n",
      "2007-08-08 00:00:002\n",
      "2007-08-09 00:00:002\n",
      "2007-08-15 00:00:002\n",
      "2007-08-16 00:00:002\n",
      "2007-08-17 00:00:002\n",
      "2007-08-21 00:00:002\n",
      "2007-08-22 00:00:002\n",
      "2007-08-24 00:00:002\n",
      "2007-08-28 00:00:002\n",
      "2007-09-04 00:00:002\n",
      "2007-09-05 00:00:002\n",
      "2007-09-06 00:00:002\n",
      "2007-09-12 00:00:002\n",
      "2007-09-18 00:00:002\n",
      "2007-09-19 00:00:002\n",
      "2007-09-24 00:00:002\n",
      "2007-09-25 00:00:002\n",
      "2007-10-04 00:00:002\n",
      "2007-10-09 00:00:002\n",
      "2009-05-28 00:00:002\n",
      "2009-06-02 00:00:002\n",
      "2009-06-03 00:00:002\n",
      "2009-06-05 00:00:002\n",
      "2009-06-12 00:00:002\n",
      "2009-06-15 00:00:002\n",
      "2009-06-19 00:00:002\n",
      "2009-06-22 00:00:002\n",
      "2009-06-26 00:00:002\n",
      "2009-06-29 00:00:002\n",
      "2009-07-06 00:00:002\n",
      "2009-07-10 00:00:002\n",
      "2009-07-13 00:00:002\n",
      "2009-07-17 00:00:002\n",
      "2009-07-24 00:00:002\n",
      "2009-07-27 00:00:002\n",
      "2009-07-31 00:00:002\n",
      "2009-08-07 00:00:002\n",
      "2009-08-13 00:00:002\n",
      "2009-08-25 00:00:002\n",
      "2009-08-27 00:00:002\n",
      "2009-09-03 00:00:002\n",
      "2009-09-14 00:00:002\n",
      "2009-09-17 00:00:002\n",
      "2009-09-25 00:00:002\n",
      "2009-10-01 00:00:002\n",
      "2011-06-10 00:00:002\n",
      "2011-06-17 00:00:002\n",
      "2011-06-24 00:00:002\n",
      "2011-06-30 00:00:002\n",
      "2011-07-11 00:00:002\n",
      "2011-07-15 00:00:002\n",
      "2011-07-25 00:00:002\n",
      "2011-07-29 00:00:002\n",
      "2011-08-05 00:00:002\n",
      "2011-08-12 00:00:002\n",
      "2011-08-19 00:00:002\n",
      "2011-08-26 00:00:002\n",
      "2011-09-01 00:00:002\n",
      "2011-09-02 00:00:002\n",
      "2011-09-12 00:00:002\n",
      "2011-09-16 00:00:002\n",
      "2011-09-23 00:00:002\n",
      "2011-09-30 00:00:002\n",
      "2013-06-07 00:00:002\n",
      "2013-06-14 00:00:002\n",
      "2013-06-21 00:00:002\n",
      "2013-06-27 00:00:002\n",
      "2013-06-28 00:00:002\n",
      "2013-07-08 00:00:002\n",
      "2013-07-12 00:00:002\n",
      "2013-07-19 00:00:002\n",
      "2013-07-25 00:00:002\n",
      "2013-08-01 00:00:002\n",
      "2013-08-08 00:00:002\n",
      "2013-08-15 00:00:002\n",
      "2013-08-22 00:00:002\n",
      "2013-08-29 00:00:002\n",
      "2013-09-06 00:00:002\n",
      "2013-09-12 00:00:002\n",
      "2013-09-19 00:00:002\n",
      "2013-09-26 00:00:002\n"
     ]
    }
   ],
   "source": [
    "# Check whether unique id works\n",
    "\n",
    "train_dates = train.date_station_id.unique()\n",
    "\n",
    "weather_dates = set(weather.date_station_id)\n",
    "\n",
    "for day in train_dates:\n",
    "    if day in weather_dates:\n",
    "        print day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'M' in weather data is a missing value; convert all instances to np.nan\n",
    "weather.replace(to_replace='M', value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sunrise and sunset values are omitted for the second reading of each day; this will allow us to backfill them all\n",
    "# First convert empty cells to np.nan\n",
    "weather.replace(to_replace='-', value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Codesum column has many empty values; convert all empty cells to np.nan\n",
    "weather.replace(to_replace=' ', value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station               0\n",
       "Tmax                  0\n",
       "Tmin                  0\n",
       "Tavg                  6\n",
       "Depart              736\n",
       "DewPoint              0\n",
       "WetBulb               4\n",
       "Heat                  6\n",
       "Cool                  6\n",
       "Sunrise             736\n",
       "Sunset              736\n",
       "CodeSum             756\n",
       "Depth               736\n",
       "Water1             1472\n",
       "SnowFall            736\n",
       "PrecipTotal           2\n",
       "StnPressure           4\n",
       "SeaLevel              6\n",
       "ResultSpeed           0\n",
       "ResultDir             0\n",
       "AvgSpeed              2\n",
       "date_station_id       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now identify number of missing values in each column\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop columns with over half NANs, *except* Sunrise and Sunset (those will be backfilled)\n",
    "\n",
    "weather.drop(['Depart', 'Depth', 'Water1', 'SnowFall', 'CodeSum'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For remaining NANs, use backfill to impute values\n",
    "\n",
    "weather.fillna(method='pad', limit=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'T' in weather data is trace precipitation; convert all instances to zero\n",
    "\n",
    "weather.replace(to_replace='  T', value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station             object\n",
       "Tmax                 int64\n",
       "Tmin                 int64\n",
       "Tavg                object\n",
       "DewPoint             int64\n",
       "WetBulb             object\n",
       "Heat                object\n",
       "Cool                object\n",
       "Sunrise             object\n",
       "Sunset              object\n",
       "PrecipTotal         object\n",
       "StnPressure         object\n",
       "SeaLevel            object\n",
       "ResultSpeed        float64\n",
       "ResultDir            int64\n",
       "AvgSpeed            object\n",
       "date_station_id     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that missing values and strings have been removed from data, convert columns to numeric\n",
    "\n",
    "weather['Tavg'] = pd.to_numeric(weather.Tavg)\n",
    "weather['WetBulb'] = pd.to_numeric(weather.WetBulb)\n",
    "weather['Heat'] = pd.to_numeric(weather.Heat)\n",
    "weather['Cool'] = pd.to_numeric(weather.Cool)\n",
    "weather['Sunrise'] = pd.to_numeric(weather.Sunrise)\n",
    "weather['Sunset'] = pd.to_numeric(weather.Sunset)\n",
    "weather['PrecipTotal'] = pd.to_numeric(weather.PrecipTotal)\n",
    "weather['StnPressure'] = pd.to_numeric(weather.StnPressure)\n",
    "weather['SeaLevel'] = pd.to_numeric(weather.SeaLevel)\n",
    "weather['AvgSpeed'] = pd.to_numeric(weather.AvgSpeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather.to_csv('../Assets/weather_clean.csv', encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
